{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOxdBNPwJiKpNU9i4UM5YV2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","import random\n","\n","SEED = 42\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","iris = load_iris()\n","X = iris.data\n","y = iris.target\n","target_names = iris.target_names\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)\n","\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","results = []\n","for k in range(1, 11):\n","    model = KNeighborsClassifier(n_neighbors=k)\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","\n","    acc = accuracy_score(y_test, y_pred)\n","    results.append((k, acc))\n","\n","    print(f\"\\nK = {k}\")\n","    print(\"Accuracy:\", round(acc, 4))\n","    print(\"Classification Report:\")\n","    print(classification_report(y_test, y_pred, target_names=target_names))\n","\n","results_df = pd.DataFrame(results, columns=[\"K\", \"Accuracy\"])\n","print(\"\\nAccuracy for different K values:\")\n","print(results_df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NcMKHmyeOljC","executionInfo":{"status":"ok","timestamp":1756111328562,"user_tz":-330,"elapsed":124,"user":{"displayName":"Abinayasri Murugan","userId":"13327265448263354566"}},"outputId":"47e5bd6c-bc3f-49d6-c921-f18085ca955c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","K = 1\n","Accuracy: 0.9778\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","      setosa       1.00      1.00      1.00        19\n","  versicolor       1.00      0.92      0.96        13\n","   virginica       0.93      1.00      0.96        13\n","\n","    accuracy                           0.98        45\n","   macro avg       0.98      0.97      0.97        45\n","weighted avg       0.98      0.98      0.98        45\n","\n","\n","K = 2\n","Accuracy: 0.9778\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","      setosa       1.00      1.00      1.00        19\n","  versicolor       0.93      1.00      0.96        13\n","   virginica       1.00      0.92      0.96        13\n","\n","    accuracy                           0.98        45\n","   macro avg       0.98      0.97      0.97        45\n","weighted avg       0.98      0.98      0.98        45\n","\n","\n","K = 3\n","Accuracy: 1.0\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","      setosa       1.00      1.00      1.00        19\n","  versicolor       1.00      1.00      1.00        13\n","   virginica       1.00      1.00      1.00        13\n","\n","    accuracy                           1.00        45\n","   macro avg       1.00      1.00      1.00        45\n","weighted avg       1.00      1.00      1.00        45\n","\n","\n","K = 4\n","Accuracy: 0.9778\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","      setosa       1.00      1.00      1.00        19\n","  versicolor       0.93      1.00      0.96        13\n","   virginica       1.00      0.92      0.96        13\n","\n","    accuracy                           0.98        45\n","   macro avg       0.98      0.97      0.97        45\n","weighted avg       0.98      0.98      0.98        45\n","\n","\n","K = 5\n","Accuracy: 1.0\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","      setosa       1.00      1.00      1.00        19\n","  versicolor       1.00      1.00      1.00        13\n","   virginica       1.00      1.00      1.00        13\n","\n","    accuracy                           1.00        45\n","   macro avg       1.00      1.00      1.00        45\n","weighted avg       1.00      1.00      1.00        45\n","\n","\n","K = 6\n","Accuracy: 1.0\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","      setosa       1.00      1.00      1.00        19\n","  versicolor       1.00      1.00      1.00        13\n","   virginica       1.00      1.00      1.00        13\n","\n","    accuracy                           1.00        45\n","   macro avg       1.00      1.00      1.00        45\n","weighted avg       1.00      1.00      1.00        45\n","\n","\n","K = 7\n","Accuracy: 1.0\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","      setosa       1.00      1.00      1.00        19\n","  versicolor       1.00      1.00      1.00        13\n","   virginica       1.00      1.00      1.00        13\n","\n","    accuracy                           1.00        45\n","   macro avg       1.00      1.00      1.00        45\n","weighted avg       1.00      1.00      1.00        45\n","\n","\n","K = 8\n","Accuracy: 1.0\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","      setosa       1.00      1.00      1.00        19\n","  versicolor       1.00      1.00      1.00        13\n","   virginica       1.00      1.00      1.00        13\n","\n","    accuracy                           1.00        45\n","   macro avg       1.00      1.00      1.00        45\n","weighted avg       1.00      1.00      1.00        45\n","\n","\n","K = 9\n","Accuracy: 1.0\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","      setosa       1.00      1.00      1.00        19\n","  versicolor       1.00      1.00      1.00        13\n","   virginica       1.00      1.00      1.00        13\n","\n","    accuracy                           1.00        45\n","   macro avg       1.00      1.00      1.00        45\n","weighted avg       1.00      1.00      1.00        45\n","\n","\n","K = 10\n","Accuracy: 1.0\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","      setosa       1.00      1.00      1.00        19\n","  versicolor       1.00      1.00      1.00        13\n","   virginica       1.00      1.00      1.00        13\n","\n","    accuracy                           1.00        45\n","   macro avg       1.00      1.00      1.00        45\n","weighted avg       1.00      1.00      1.00        45\n","\n","\n","Accuracy for different K values:\n","    K  Accuracy\n","0   1  0.977778\n","1   2  0.977778\n","2   3  1.000000\n","3   4  0.977778\n","4   5  1.000000\n","5   6  1.000000\n","6   7  1.000000\n","7   8  1.000000\n","8   9  1.000000\n","9  10  1.000000\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"CkBm9UKoSPgc"},"execution_count":null,"outputs":[]}]}